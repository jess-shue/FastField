---
title: "Write a .csv file into `./output/`, combining dplyr::selected spreadsheets from each workbook in `./input/`"
author: Mauro Lepore and Jess Shue
output: 
  rmarkdown::html_document :
    toc: true
    toc_depth: 3
    theme: united
params:
  input_dir: "input"
  output_dir: "output"
---

```{r setup, include=FALSE}
set.seed(1014)
options(digits = 3)

knitr::opts_chunk$set(
  echo = TRUE,
  comment = "#>",
  collapse = TRUE,
  cache = TRUE,
  out.width = "70%",
  fig.align = "center",
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold"
)
```

# Overview

This document wrangles fieldwork data collected with the software [FastField](http://www.fastfieldforms.com/index.html). Jess Sue designed the data structure, and the job she required is done via the function [`FastField::xl_sheets_to_csv`()](xxx add link)) of the __qcr__ package.

`FastField::xl_sheets_to_csv()` does all of this:

* Reads each spreadsheet from each workbook and maps it to a dataframe in a list of dataframes.
* Lowercases and links the names of each element of the list of dataframes.
* Keeps only these dataframes: (1) original_stems; (2) new_secondary_stems; (3)
  recruits; and (4) start_page.
* Keeps only non-empty dataframes and warns if any dataframe where dropped.
* Lowercases and links the names of each dataframe-variable.
* Drops fake stems.
* Adds the name of each spreadsheet as the value of the variable `sheet`.
* Reduces the list of dataframes to a single dataframe, by joining them.
* Adds the variable `unique_stem` to uniquely identify each stem.
* Outputs a .csv file, which name matches the name of the workbook
  where the original data comes from.

# Setup

Install __FastField__ if it is missing.

```{r}
missing <- !require(FastField)
if (missing) {
  remotes::install_github("forestgeo/FastField")
}
```

Load required packages.

```{r}
library(FastField)

# I will referr to functions' source explicitely -- as `package::function()`
library(dplyr)
library(DT)
library(fgeo.tool)
library(fs)
library(purrr)
library(readr)
library(tibble)
library(tidyr)
```

---

Hint

Check these articles if you struggle to install, load, or use R packages:

* [How to update R, RStudio and R packages with minimal effort](https://goo.gl/ALpYxX).
* [How to install packages from GitHub](https://goo.gl/eUX2Br).

---

View the contents of the `r params$input_dir` directory.

```{r}
fs::dir_ls(params$input_dir)
```

---

# Work

Do the job (the output is silent.)

```{r}
FastField::xl_sheets_to_csv(params$input_dir, params$output_dir)
```

---

Note

`FastField::xl_sheets_to_csv()` expects that the names of the spreadsheets and columns of each spreadsheet will be these ones:

```{r }
one_excel_file <- fs::dir_ls(params$input_dir)[[1]]
df_list <- fgeo.tool::ls_list_spreadsheets(one_excel_file)
purrr::map(df_list, names) %>% 
  tibble::enframe(name = "spreadsheet", value = "column names") %>% 
  tidyr::unnest() %>% 
  DT::datatable()
```

This is rigid but makes the interface extreemely simple and thus easy to use. If you change the names of the spreadsheets or the names of the columns in each spreadsheet please let me know (maurolepore@gmail.com). These are the options: (1) To make `FastField::xl_sheets_to_csv()` more flexible at the cost of making it also more complex and a little harder to use; or (2) To update `FastField::xl_sheets_to_csv()` to hard-wire the new names.

---

# Review

This section reviews the output. You can safely ignore the code because the implementation details are unimportant.

Confirm that the `r params$output_dir` directory contains the expected .csv files.

```{r}
csv_files_in_output <- fs::dir_ls(params$output_dir, regexp = ".csv$")
csv_files_in_output
```

Combine and the resulting .csv files to make it easier to explore the data.

```{r, message=FALSE}
names_of_csv_files <- sub(".csv$", "", basename(csv_files_in_output))

combined <- csv_files_in_output %>% 
  purrr::map(read_csv) %>% 
  purrr::set_names(names_of_csv_files) %>% 
  tibble::enframe(name = "csv_filename") %>% 
  tidyr::unnest()

DT::datatable(combined)
```

Observe that some tags have missing values.

```{r}
combined %>% 
  dplyr::select(unique_stem, matches("stem|tag|dbh"), everything()) %>% 
  dplyr::filter(is.na(tag))
```

Removing missing tags.

```{r}
combined <- dplyr::filter(combined, !is.na(tag))
```

Identify stems that were skipped in this census.

```{r}
sampled_before <- combined %>% 
  dplyr::filter(sheet == "orignal_stems") %>% 
  dplyr::pull(unique_stem) %>% 
  unique()
sampled_now <- combined %>% 
  dplyr::filter(sheet != "orignal_stems") %>% 
  dplyr::pull(unique_stem) %>% 
  unique()
skipped_stems <- setdiff(sampled_before, sampled_now)

combined %>% 
  dplyr::select(unique_stem, sheet, matches("stem|tag|dbh"), everything()) %>% 
  dplyr::filter(unique_stem %in% skipped_stems)
```

Identify duplicated stems.

```{r}
duplicated_stems <- combined %>% 
  dplyr::group_by(unique_stem) %>% 
  dplyr::count(unique_stem) %>% 
  dplyr::filter(n > 1) %>% 
  dplyr::pull(unique_stem) %>% 
  unique()

combined %>% 
  dplyr::select(unique_stem, sheet, matches("stem|tag|dbh"), everything()) %>% 
  dplyr::filter(unique_stem %in% duplicated_stems) %>% 
  dplyr::arrange(unique_stem)
```

---

Note

* The example dataset has all its values duplicated. That is intentional.

---

# Future work

To do more comlex checks I need more data (e.g. to check that `DBH` values are reasonable).
